---
name: ollama
version: v0.6.6
base: core24
summary: Get up and running with large language models locally.
description: |
  Run Llama 2, Code Llama, and other models. Customize and create your own.
adopt-info: ollama
grade: stable
confinement: strict
license: MIT
platforms:
  amd64:
  arm64:

package-repositories:
  - type: apt
    formats: [deb]
    architectures: [amd64]
    path: /
    key-id: EB693B3035CD5710E231E123A4B469963BF863CC
    url: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64
  - type: apt
    formats: [deb]
    architectures: [arm64]
    path: /
    key-id: EB693B3035CD5710E231E123A4B469963BF863CC
    url: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/arm64

apps:
  ollama:
    command: bin/snap_launcher.sh
    plugs:
      - home
      - removable-media
      - network
      - network-bind
      - opengl # grants also CUDA based GPU access
    environment:
      LD_LIBRARY_PATH: "$SNAP/lib/ollama:$SNAP/usr/lib/$CRAFT_ARCH_TRIPLET_BUILD_FOR:/var/lib/snapd/lib/gl${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"
  listener:
    command: bin/snap_launcher.sh serve
    daemon: simple
    install-mode: enable
    restart-condition: on-failure
    refresh-mode: restart
    plugs:
      - home
      - removable-media
      - network
      - network-bind
      - opengl
    environment:
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      LD_LIBRARY_PATH: "$SNAP/lib/ollama:$SNAP/usr/lib/$CRAFT_ARCH_TRIPLET_BUILD_FOR:/var/lib/snapd/lib/gl${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"

parts:
  launcher:
    plugin: dump
    source: ./snap/local
    organize:
      snap_launcher.sh: bin/snap_launcher.sh
  ollama:
    plugin: go
    source: https://github.com/ollama/ollama.git
    source-type: git
    source-tag: $SNAPCRAFT_PROJECT_VERSION
    # build packages (not staged) because ollama copies in cudnn, cublas etc
    build-packages:
      - git
      - gcc
      - cmake
      - sed
      - libcudnn9-cuda-12
      - libcudnn9-dev-cuda-12
      - on amd64:
        - cuda-cudart-dev-12-8
        - cuda-driver-dev-12-8
        - cuda-toolkit-12-8
        - nvidia-cuda-dev
        - libcublas-12-8
        - libcublas-dev-12-8
        - tensorrt-libs
        - tensorrt-dev
    build-snaps:
      - go/stable
    build-environment:
      - LD_LIBRARY_PATH: "/usr/lib/${CRAFT_ARCH_TRIPLET_BUILD_FOR}/nvidia/:/usr/local/cuda/lib64/${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"
      - PATH: "/usr/local/cuda/bin${PATH:+:$PATH}"
    override-pull: |
      craftctl default
      last_committed_tag="$(git describe --tags --abbrev=0)"
      last_committed_tag_ver="$(echo ${last_committed_tag} | sed 's/v//')"
      craftctl set version="$(git describe --tags | sed 's/v//')"
    override-build: |
      cmake -B build
      cmake --build build --config Release
      mkdir -p $CRAFT_PART_INSTALL/lib/ollama
      cp -rp build/lib/ollama/* $CRAFT_PART_INSTALL/lib/ollama
      craftctl default

  libs:
    plugin: nil
    stage-packages:
      - libcudnn9-cuda-12
      - on amd64:
        - libcublas-12-8
        - cuda-libraries-12-8
        - libcudart12
        - libcublaslt12
        - libcublas12
    stage:
      - -usr/local
